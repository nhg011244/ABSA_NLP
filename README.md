# ğŸ›ï¸ PhÃ¢n TÃ­ch Cáº£m XÃºc Äa KhÃ­a Cáº¡nh Tiáº¿ng Viá»‡t (Vietnamese ABSA)

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![Transformers](https://img.shields.io/badge/Transformers-HuggingFace-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-%23FE4B4B.svg?style=flat&logo=streamlit&logoColor=white)

Äá»“ Ã¡n Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (NLP) táº­p trung giáº£i quyáº¿t bÃ i toÃ¡n **Aspect-Based Sentiment Analysis (ABSA)** trÃªn táº­p dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ sáº£n pháº©m thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ (Shopee) báº±ng tiáº¿ng Viá»‡t.

Dá»± Ã¡n Ä‘á»‘i sÃ¡nh hiá»‡u nÄƒng giá»¯a mÃ´ hÃ¬nh há»c sÃ¢u tuáº§n tá»± cÆ¡ sá»Ÿ (**BiLSTM-Attention**) vÃ  kiáº¿n trÃºc tá»± chÃº Ã½ tiÃªn tiáº¿n (**PhoBERT**), Ä‘á»“ng thá»i triá»ƒn khai má»™t giao diá»‡n Web Demo thá»±c táº¿.

## ğŸŒŸ TÃ­nh NÄƒng Ná»•i Báº­t

* **Tiá»n xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t:** TÃ­ch há»£p bá»™ tá»« Ä‘iá»ƒn chuáº©n hÃ³a Teencode tá»± xÃ¢y dá»±ng vÃ  bá»™ tÃ¡ch tá»« `underthesea`.
* **PhÃ¢n loáº¡i 8 KhÃ­a cáº¡nh (Aspects):** `Price` (GiÃ¡ cáº£), `Shipping` (Giao hÃ ng), `Outlook` (HÃ¬nh thá»©c), `Quality` (Cháº¥t lÆ°á»£ng), `Size` (KÃ­ch cá»¡), `Shop_Service` (Dá»‹ch vá»¥), `General` (ÄÃ¡nh giÃ¡ chung), `Others` (KhÃ¡c).
* **PhÃ¢n cá»±c 4 Sáº¯c thÃ¡i (Polarities):** TÃ­ch cá»±c (Positive), TiÃªu cá»±c (Negative), Trung tÃ­nh (Neutral), KhÃ´ng Ä‘á» cáº­p (None).
* **Xá»­ lÃ½ Máº¥t cÃ¢n báº±ng lá»›p (Class Imbalance):** Ãp dá»¥ng ká»¹ thuáº­t Class Weights vÃ o hÃ m Weighted Cross-Entropy Loss.
* **Giao diá»‡n Web TÆ°Æ¡ng tÃ¡c:** TÃ­ch há»£p Streamlit cho phÃ©p dá»± Ä‘oÃ¡n cáº£m xÃºc thá»i gian thá»±c (Real-time Inference).

## ğŸ“Š Káº¿t Quáº£ ÄÃ¡nh GiÃ¡ (Táº­p Test)

Sá»­ dá»¥ng Ä‘á»™ Ä‘o **Macro F1-Score** Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng. MÃ´ hÃ¬nh PhoBERT thá»ƒ hiá»‡n sá»± vÆ°á»£t trá»™i trong viá»‡c náº¯m báº¯t ngá»¯ cáº£nh tiáº¿ng Viá»‡t phá»©c táº¡p.

| MÃ´ hÃ¬nh | Average Training Loss | Macro F1-Score (Tá»•ng thá»ƒ) |
| :--- | :---: | :---: |
| **BiLSTM-Attention** | 0.0161 | 0.6444 |
| **PhoBERT (Fine-tuned)** | 0.1085 | **0.7013** |

*(Äá»“ thá»‹ so sÃ¡nh Loss vÃ  báº£ng F1-Score chi tiáº¿t tá»«ng khÃ­a cáº¡nh xem trong file bÃ¡o cÃ¡o hoáº·c Notebook).*

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```text
â”œâ”€â”€ datasets_cleaned/       # Chá»©a dá»¯ liá»‡u train/val/test Ä‘Ã£ qua tiá»n xá»­ lÃ½
â”œâ”€â”€ images/                 # Chá»©a cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan hÃ³a (Learning curves, Data distribution)
â”œâ”€â”€ model/                  # Chá»©a file kiáº¿n trÃºc máº¡ng nÆ¡-ron
â”‚   â”œâ”€â”€ bi_lstm.py          # Khá»Ÿi táº¡o class BiLSTMAttentionABSA
â”‚   â””â”€â”€ pho_bert.py         # Khá»Ÿi táº¡o class PhoBERT_ABSA
â”œâ”€â”€ saved_models/           # (Ignored) NÆ¡i lÆ°u trá»¯ trá»ng sá»‘ mÃ´ hÃ¬nh tá»‘t nháº¥t (.pth)
â”œâ”€â”€ app.py                  # MÃ£ nguá»“n giao diá»‡n Web Demo báº±ng Streamlit
â”œâ”€â”€ eda.py                  # MÃ£ nguá»“n phÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a dá»¯ liá»‡u (EDA)
â”œâ”€â”€ text_preprocessing.py   # CÃ¡c hÃ m lÃ m sáº¡ch vÄƒn báº£n, chuáº©n hÃ³a teencode
â”œâ”€â”€ train.ipynb             # Notebook huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”œâ”€â”€ test.ipynb              # Notebook cháº¡y Ä‘á»‘i sÃ¡nh vÃ  in káº¿t quáº£ dá»± Ä‘oÃ¡n
â”œâ”€â”€ requirements.txt        # Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
â””â”€â”€ README.md               # TÃ i liá»‡u mÃ´ táº£ dá»± Ã¡n

ğŸš€ HÆ°á»›ng Dáº«n CÃ i Äáº·t vÃ  Sá»­ Dá»¥ng
BÆ°á»›c 1: Clone Repository
```bash
git clone [https://github.com/nhg011244/ABSA_NLP.git](https://github.com/nhg011244/ABSA_NLP.git)

BÆ°á»›c 2: CÃ i Ä‘áº·t thÆ° viá»‡n
Khuyáº¿n nghá»‹ sá»­ dá»¥ng mÃ´i trÆ°á»ng áº£o (Virtual Environment) Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t thÆ° viá»‡n.

pip install -r requirements.txt

BÆ°á»›c 3: Cháº¡y giao diá»‡n Web Demo
Äáº£m báº£o báº¡n Ä‘Ã£ cÃ³ file trá»ng sá»‘ phobert_absa_weights.pth náº±m trong thÆ° má»¥c saved_models/. Sau Ä‘Ã³ cháº¡y lá»‡nh:

streamlit run app.py
TrÃ¬nh duyá»‡t sáº½ tá»± Ä‘á»™ng má»Ÿ trang Web Demo táº¡i Ä‘á»‹a chá»‰: http://localhost:8501