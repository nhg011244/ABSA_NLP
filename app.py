import streamlit as st
import torch
import re
from underthesea import word_tokenize
from transformers import AutoTokenizer
import pandas as pd

from model.pho_bert import PhoBERT_ABSA

st.set_page_config(page_title="Demo ABSA - PhoBERT", page_icon="üõçÔ∏è", layout="centered")

st.title("üõçÔ∏è H·ªá th·ªëng Ph√¢n t√≠ch ƒê√°nh gi√° ƒêa kh√≠a c·∫°nh")
st.markdown("""
H·ªá th·ªëng s·ª≠ d·ª•ng m√¥ h√¨nh **PhoBERT** ƒë·ªÉ t·ª± ƒë·ªông b√≥c t√°ch c·∫£m x√∫c kh√°ch h√†ng th√†nh 8 kh√≠a c·∫°nh ƒë·ªôc l·∫≠p. 
D·ª± √°n cu·ªëi k·ª≥ m√¥n X·ª≠ l√Ω Ng√¥n ng·ªØ T·ª± nhi√™n.
""")

teen_code_dict = {
    "sp": "s·∫£n ph·∫©m", "sz": "k√≠ch c·ª°", "size": "k√≠ch c·ª°", "ƒëc": "ƒë∆∞·ª£c",
    "k": "kh√¥ng", "ko": "kh√¥ng", "kh": "kh√¥ng", "auth": "ch√≠nh h√£ng",
    "rep": "h√†ng gi·∫£", "ƒë·∫πp": "ƒë·∫πp", "okela": "t·ªët", "oke": "t·ªët",
    "ok": "t·ªët", "tl": "tr·∫£ l·ªùi", "ib": "nh·∫Øn tin", "shop": "c·ª≠a h√†ng",
    "nv": "nh√¢n vi√™n", "ship": "giao h√†ng", "shipper": "ng∆∞·ªùi giao h√†ng",
    "bt": "b√¨nh th∆∞·ªùng", "vs": "v·ªõi"
}

def preprocess_text(text):
    if not isinstance(text, str): return ""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
    text = re.sub(r'[^\w\s]', ' ', text)
    words = text.split()
    standardized_words = [teen_code_dict.get(word, word) for word in words]
    text = ' '.join(standardized_words)
    text = re.sub(r'\s+', ' ', text).strip()
    return word_tokenize(text, format="text")

@st.cache_resource
def load_model():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")
    model = PhoBERT_ABSA().to(device)
    
    model.load_state_dict(torch.load('saved_models/phobert_absa_weights.pth', map_location=device))
    model.eval()
    return tokenizer, model, device

tokenizer, model, device = load_model()

user_input = st.text_area("üí¨ Nh·∫≠p b√¨nh lu·∫≠n c·ªßa kh√°ch h√†ng v√†o ƒë√¢y:", 
                          value="gi√†y x·ªãn form √¥m ch√¢n ƒë·∫πp, nh∆∞ng shop rep tin nh·∫Øn ch·∫≠m qu√°", 
                          height=100)

if st.button("üöÄ Ph√¢n T√≠ch Ngay"):
    if user_input.strip() == "":
        st.warning("Vui l√≤ng nh·∫≠p b√¨nh lu·∫≠n!")
    else:
        with st.spinner('M√¥ h√¨nh ƒëang suy nghƒ©...'):
            cleaned_text = preprocess_text(user_input)
            
            encoding = tokenizer(
                cleaned_text, add_special_tokens=True, max_length=128,
                padding='max_length', truncation=True, return_attention_mask=True, return_tensors='pt'
            )
            
            input_ids = encoding['input_ids'].to(device)
            attention_mask = encoding['attention_mask'].to(device)
            
            with torch.no_grad():
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            
            aspects = ['Price (Gi√° c·∫£)', 'Shipping (Giao h√†ng)', 'Outlook (H√¨nh th·ª©c)', 
                       'Quality (Ch·∫•t l∆∞·ª£ng)', 'Size (K√≠ch c·ª°)', 'Shop_Service (D·ªãch v·ª•)', 
                       'General (ƒê√°nh gi√° chung)', 'Others (Kh√°c)']
            
            label_map = {
                0: ('Ti√™u c·ª±c', 'üî¥'), 
                1: ('T√≠ch c·ª±c', 'üü¢'), 
                2: ('Trung t√≠nh', 'üü°'), 
                3: ('Kh√¥ng ƒë·ªÅ c·∫≠p', '‚ö™')
            }
            
            st.success("‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t!")
            st.markdown(f"**VƒÉn b·∫£n sau khi l√†m s·∫°ch (D√†nh cho ki·ªÉm tra):** `{cleaned_text}`")
            
            results_data = []
            found_aspects = False
            
            for i, aspect in enumerate(aspects):
                pred_label = torch.argmax(outputs[i], dim=1).item()
                if pred_label != 3:
                    found_aspects = True
                    text_label, icon = label_map[pred_label]
                    results_data.append({"Kh√≠a c·∫°nh": aspect, "ƒê√°nh gi√°": f"{icon} {text_label}"})
            
            if found_aspects:
                df_results = pd.DataFrame(results_data)
                st.table(df_results)
            else:
                st.info("M√¥ h√¨nh kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c kh√≠a c·∫°nh khen/ch√™ n√†o r√µ r√†ng trong c√¢u n√†y.")